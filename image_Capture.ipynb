{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e51a00b2-b723-46a0-8354-b7fcecae0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60eebc3f-e0ab-4312-afd7-7e2737df7eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Active local webcam\n",
    "camera = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c98655d-b213-4413-92cb-9e2a71b230f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Image saved to list\n",
      "Exited camera window\n"
     ]
    }
   ],
   "source": [
    "# Init base variable \n",
    "# List to store images from Image Catcher\n",
    "images = []\n",
    "# Current file number to save image\n",
    "file_number = 0\n",
    "# Get current directory path\n",
    "current_dir = os.getcwd()\n",
    "# Check if 'test_iamges' folder exists, if not create folder\n",
    "if 'test_images' not in os.listdir(path=current_dir):\n",
    "    os.mkdir('test_images')\n",
    "    \n",
    "while True:\n",
    "    # Get video frame\n",
    "    _, camera_frame = camera.read()\n",
    "    # Draw rectangle on catched image - show area of proper photo\n",
    "    image_with_border = cv2.rectangle(camera_frame, (100, 100), (500, 500), (255,0,0), 2)\n",
    "    # Show image with drawn border\n",
    "    cv2.imshow(\"Image Catcher\", image_with_border)\n",
    "    # Wait for 1[s] to take an action\n",
    "    pressed_key = cv2.waitKey(1)\n",
    "    # If 'q' button clicked, exit \"Image Catcher\"\n",
    "    if pressed_key == 113:\n",
    "        print('Exited camera window')\n",
    "        # Close all opend Windows\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    # If 'space' button clicked, take an image\n",
    "    if pressed_key == 32:\n",
    "        # Get clear frame (without border)\n",
    "        _, image = camera.read()\n",
    "        # Append list with taken image of size 500x500\n",
    "        images.append(image[100:500, 100:500])     \n",
    "        # Set path to save taken image\n",
    "        image_name = f'test_images/testing_image_{file_number}.jpg'\n",
    "        # Save image \n",
    "        cv2.imwrite(image_name, image[100:500, 100:500])\n",
    "        # Iterate file name by 1\n",
    "        file_number += 1\n",
    "        # Print information about saved image\n",
    "        print(\"Image saved to list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cf6c44a-a8e5-45c7-b17d-47711d408790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Release used device - built-in camera\n",
    "camera.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "13eb6446-ca68-4e37-8733-529a4f64525f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "1/1 [==============================] - 0s 175ms/step\n",
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 111ms/step\n",
      "1/1 [==============================] - 0s 108ms/step\n",
      "1/1 [==============================] - 0s 317ms/step\n",
      "1/1 [==============================] - 0s 279ms/step\n",
      "1/1 [==============================] - 0s 132ms/step\n",
      "1/1 [==============================] - 0s 343ms/step\n",
      "1/1 [==============================] - 0s 116ms/step\n",
      "1/1 [==============================] - 0s 145ms/step\n",
      "1/1 [==============================] - 0s 109ms/step\n",
      "1/1 [==============================] - 0s 137ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n"
     ]
    }
   ],
   "source": [
    "predict_emotion = []\n",
    "predicted_values = []\n",
    "# Load pretrain model of CNN\n",
    "model = load_model(os.path.join('models', 'pain_detection_model_VGG16.h5'))\n",
    "# Loop through images list\n",
    "for index, img in enumerate(images):\n",
    "    # Resize image to 256x256 size -> expected size by CNN model\n",
    "    resized_img = tf.image.resize(img, (224,224))\n",
    "    # Predict pain image\n",
    "    predict_emotion.append(model.predict(np.expand_dims(resized_img/255, 0)))\n",
    "    predicted_values.append(predict_emotion[index][0][0])\n",
    "    # Show iamges from list in RGB colors\n",
    "    #cv2.imshow(f'Image_{index}: {predict_emotion[index][0][0]}', img)\n",
    "\n",
    "# Waiting for key action\n",
    "cv2.waitKey(0)\n",
    "# Closing all opend windows with images\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "649ea809-13e6-422c-9cce-3fc0b1c192f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print image using matplotlib-pyplot\n",
    "\n",
    "fig = plt.figure()\n",
    "len(images)%3 \n",
    "for i in range(0, len(images)):\n",
    "    plt.subplot(round(len(images)/4), 4, i+1)\n",
    "    plt.imshow(cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB))\n",
    "    plt.gca().set_title('Tested image: %.3f' %predicted_values[i], fontsize=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cad55410-6a0d-4b7d-829c-1fc84580e983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(len(images)/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3dc3918d-0215-41d3-9aec-152f785bf533",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "fig_1 = plt.figure()\n",
    "plt.scatter(np.arange(0, len(predicted_values),1, dtype = int), np.array(predicted_values),  color='teal', marker ='s', label='Value for each image')\n",
    "plt.plot(np.arange(0, len(predicted_values),1, dtype = int), [0.5 for i in range(len(predicted_values))], color = 'green', label='Dividing line at 0.5', linewidth=2)\n",
    "fig_1.suptitle('Pain prediction values', fontsize=20)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "fi_2 = plt.figure()\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "397a0eff-660b-4b86-ba68-08db348e868a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.29473516]], dtype=float32),\n",
       " array([[0.06853647]], dtype=float32),\n",
       " array([[0.13810997]], dtype=float32),\n",
       " array([[0.9880064]], dtype=float32),\n",
       " array([[0.11388447]], dtype=float32),\n",
       " array([[0.9945581]], dtype=float32),\n",
       " array([[0.947809]], dtype=float32),\n",
       " array([[0.97640914]], dtype=float32),\n",
       " array([[0.74176335]], dtype=float32),\n",
       " array([[0.43288973]], dtype=float32),\n",
       " array([[0.03965661]], dtype=float32),\n",
       " array([[0.00608474]], dtype=float32),\n",
       " array([[0.02003187]], dtype=float32),\n",
       " array([[0.00243415]], dtype=float32)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_emotion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5089281-b1e8-404c-8900-bbcb8ee73448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete 'test_images' directory after finshed work - optional to use\n",
    "#shutil.rmtree(os.path.join(current_dir, 'test_images'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
